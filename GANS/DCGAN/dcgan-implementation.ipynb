{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":37705,"sourceType":"datasetVersion","datasetId":29561}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Importing modules and setting hyperparameters**","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim \nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets\nfrom torchvision.utils import save_image\nimport os\nimport numpy as np \n\n\ndevice=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Hyperparameters\n\n\nBATCH_SIZE = 128\nIMG_HEIGHT = 64\nIMG_WIDTH = 64\nCHANNELS = 3\nLATENT_DIM = 100\nEPOCHS = 150\nsample_dir = './output_samples'\nmodel_dir = './output_models'\nos.makedirs(sample_dir, exist_ok=True)\nos.makedirs(model_dir, exist_ok=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Prepping Dataset**","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\n\ntransform = transforms.Compose([\n    transforms.Resize(int(IMG_HEIGHT * 1.1)),  \n    transforms.CenterCrop((IMG_HEIGHT, IMG_WIDTH)),  \n    transforms.RandomHorizontalFlip(p=0.5),  \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n])\n\ndataset = datasets.ImageFolder(root=\"/kaggle/input/celeba-dataset\", transform=transform)\n\ndataloader = DataLoader(\n    dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=16,\n    pin_memory=True,\n    prefetch_factor=4,\n    persistent_workers=True\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Creating Generator**","metadata":{}},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Linear(LATENT_DIM, 8*8*256, bias=False),\n            nn.BatchNorm1d(8*8*256),\n            nn.ReLU(True),\n            nn.Unflatten(1, (256, 8, 8)),\n\n            nn.ConvTranspose2d(256, 128, 5, 2, 2, output_padding=1, bias=False),\n            nn.BatchNorm2d(128),\n            nn.ReLU(True),\n\n            nn.ConvTranspose2d(128, 64, 5, 2, 2, output_padding=1, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(True),\n\n            nn.ConvTranspose2d(64, CHANNELS, 5, 2, 2, output_padding=1, bias=False),\n            nn.Tanh()\n        )\n\n    def forward(self, z):\n        return self.model(z)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Creating Discriminator**","metadata":{}},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(CHANNELS, 64, 5, 2, 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.3),\n\n            nn.Conv2d(64, 128, 5, 2, 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Dropout(0.3),\n\n            nn.Flatten(),\n            nn.Linear(128 * (IMG_HEIGHT // 4) * (IMG_WIDTH // 4), 1)\n        )\n\n    def forward(self, x):\n        return self.model(x)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Module init , optimizers and losses**","metadata":{}},{"cell_type":"code","source":"generator = Generator().to(device)\ndiscriminator = Discriminator().to(device)\n\ncriterion = nn.BCEWithLogitsLoss()\n\nLR_G = 0.0002\nLR_D = 0.0002\n\ngenerator_optimizer = optim.Adam(generator.parameters(), lr=LR_G, betas=(0.5, 0.999))\ndiscriminator_optimizer = optim.Adam(discriminator.parameters(), lr=LR_D, betas=(0.5, 0.999))\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**helper functions**","metadata":{}},{"cell_type":"code","source":"def generator_loss(fake_output):\n    labels = torch.ones_like(fake_output, device=device)\n    return criterion(fake_output, labels)\n\ndef discriminator_loss(real_output, fake_output):\n    real_labels = torch.ones_like(real_output, device=device)\n    fake_labels = torch.zeros_like(fake_output, device=device)\n    real_loss = criterion(real_output, real_labels)\n    fake_loss = criterion(fake_output, fake_labels)\n    return real_loss + fake_loss\n\ndef save_generated_images(images, epoch):\n    images = (images + 1) / 2  # Rescale [-1,1] to [0,1]\n    save_image(images, os.path.join(sample_dir, f'epoch_{epoch:03d}.png'), nrow=4)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Training**","metadata":{}},{"cell_type":"code","source":"best_loss = np.inf\npatience = 4\ncooldown = 0\nfactor = 0.5\nmin_lr = 1e-6\nwait = 0\n\nfor epoch in range(1, EPOCHS + 1):\n    gen_loss_epoch, disc_loss_epoch = 0.0, 0.0\n    batches = 0\n\n    for real_images, _ in dataloader:\n        real_images = real_images.to(device)\n        batch_size = real_images.size(0)\n        noise = torch.randn(batch_size, LATENT_DIM, device=device)\n\n        # ---- Train Discriminator ----\n        discriminator_optimizer.zero_grad()\n        fake_images = generator(noise)\n        real_output = discriminator(real_images)\n        fake_output = discriminator(fake_images.detach())\n        disc_loss = discriminator_loss(real_output, fake_output)\n        disc_loss.backward()\n        discriminator_optimizer.step()\n\n        # ---- Train Generator ----\n        generator_optimizer.zero_grad()\n        fake_output = discriminator(fake_images)\n        gen_loss = generator_loss(fake_output)\n        gen_loss.backward()\n        generator_optimizer.step()\n\n        gen_loss_epoch += gen_loss.item()\n        disc_loss_epoch += disc_loss.item()\n        batches += 1\n\n    gen_loss_epoch /= batches\n    disc_loss_epoch /= batches\n\n    print(f\"Epoch {epoch:03d} - Gen Loss: {gen_loss_epoch:.4f}, Disc Loss: {disc_loss_epoch:.4f}\")\n\n    # ---- Save generated images every 10 epochs ----\n    if epoch % 10 == 0:\n        with torch.no_grad():\n            fixed_noise = torch.randn(16, LATENT_DIM, device=device)\n            fake_images = generator(fixed_noise)\n            save_generated_images(fake_images, epoch)\n\n    # ---- Model checkpointing ----\n    if gen_loss_epoch < best_loss:\n        best_loss = gen_loss_epoch\n        torch.save(generator.state_dict(), os.path.join(model_dir, 'generator_best.pth'))\n        torch.save(discriminator.state_dict(), os.path.join(model_dir, 'discriminator_best.pth'))\n        wait, cooldown = 0, 0\n    else:\n        wait += 1\n        current_lr = generator_optimizer.param_groups[0]['lr']\n        if wait >= patience and current_lr > min_lr and cooldown == 0:\n            new_lr = max(current_lr * factor, min_lr)\n            print(f\"ReduceLROnPlateau: Reducing LR to {new_lr:.8f}\")\n            for param_group in generator_optimizer.param_groups:\n                param_group['lr'] = new_lr\n            for param_group in discriminator_optimizer.param_groups:\n                param_group['lr'] = new_lr\n            cooldown = patience // 2\n            wait = 0\n        if cooldown > 0:\n            cooldown -= 1\n\n    torch.save(generator.state_dict(), os.path.join(model_dir, 'generator_latest.pth'))\n    torch.save(discriminator.state_dict(), os.path.join(model_dir, 'discriminator_latest.pth'))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}